{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f5f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22345f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fafabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1db3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ChickenDiseaseClassifier.constants import *\n",
    "from ChickenDiseaseClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "    \n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"Chicken-fecal-images\")\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83609feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ac75b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "        tb_logger = TensorBoardLogger(\n",
    "            save_dir=self.config.tensorboard_root_log_dir,\n",
    "            name=f\"tb_logs_at_{timestamp}\"\n",
    "        )\n",
    "\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=self.config.root_dir,\n",
    "            filename=\"best-checkpoint\",\n",
    "            save_top_k=1,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\"\n",
    "        )\n",
    "\n",
    "        return tb_logger, checkpoint_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ef1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d583964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_base_model(self):\n",
    "        self.model = torch.load(self.config.updated_base_model_path)\n",
    "    def train_valid_dataloader(self):\n",
    "        h, w = self.config.params_image_size[:2]\n",
    "\n",
    "        base_transform = transforms.Compose([\n",
    "            transforms.Resize((h, w)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.Resize((h, w)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(40),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],\n",
    "                    std=[0.229, 0.224, 0.225]\n",
    "                )\n",
    "            ])\n",
    "        else:\n",
    "            train_transform = base_transform\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(\n",
    "            root=self.config.training_data,\n",
    "            transform=train_transform\n",
    "        )\n",
    "\n",
    "        val_size = int(0.2 * len(full_dataset))\n",
    "        train_size = len(full_dataset) - val_size\n",
    "\n",
    "        train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "        self.val_loader = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: torch.nn.Module):\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "    def train(self, callbacks):\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=self.config.params_epochs,\n",
    "            callbacks=callbacks,\n",
    "            accelerator=\"auto\"\n",
    "        )\n",
    "\n",
    "        trainer.fit(\n",
    "            self.model,\n",
    "            train_dataloaders=self.train_loader,\n",
    "            val_dataloaders=self.val_loader\n",
    "        )\n",
    "\n",
    "        trainer.save_checkpoint(self.config.trained_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9964cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-12-31 10:46:45,582: INFO: common: yaml file: config\\config.yaml loaded succefully]\n",
      "[2025-12-31 10:46:45,584: INFO: common: yaml file: params.yaml loaded succefully]\n",
      "[2025-12-31 10:46:45,585: INFO: common: created directory at: artifacts]\n",
      "[2025-12-31 10:46:45,585: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2025-12-31 10:46:45,586: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2025-12-31 10:46:45,587: INFO: common: created directory at: artifacts\\training]\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torchvision.models.vgg.VGG was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torchvision.models.vgg.VGG])` or the `torch.serialization.safe_globals([torchvision.models.vgg.VGG])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     11\u001b[39m     training.train(\n\u001b[32m     12\u001b[39m         callback_list=callback_list\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m training_config = config.get_training_config()\n\u001b[32m      8\u001b[39m training = Training(config=training_config)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m training.train_valid_dataloader\n\u001b[32m     11\u001b[39m training.train(\n\u001b[32m     12\u001b[39m     callback_list=callback_list\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mTraining.get_base_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_base_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdated_base_model_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Games\\SomeShittyStuff\\ChickenDiseaseQualification\\Chicken-Disease-Qualification\\.venv\\Lib\\site-packages\\torch\\serialization.py:1529\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1521\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1522\u001b[39m                     opened_zipfile,\n\u001b[32m   1523\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1526\u001b[39m                     **pickle_load_args,\n\u001b[32m   1527\u001b[39m                 )\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1531\u001b[39m             opened_zipfile,\n\u001b[32m   1532\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1535\u001b[39m             **pickle_load_args,\n\u001b[32m   1536\u001b[39m         )\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torchvision.models.vgg.VGG was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torchvision.models.vgg.VGG])` or the `torch.serialization.safe_globals([torchvision.models.vgg.VGG])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_dataloader\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94371b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
